library("openxlsx")
library("Hmisc")
library("openxlsx")
library("Hmisc")
library("tidyverse")
data<-read.xlsx("C:/Users/USER/Desktop/ARG taxon correlation.xlsx",sheet=1,rowNames=T,sep.names=" ")
View(data)
#計算出現次數
data_clean<-data
data_clean[data_clean!=0]<-1
data_clean$times_discover_in_all<-apply(data_clean,1,sum)
data$times_discoverl<-data_clean$times_discover_in_all
data$times_discover<-data_clean$times_discover_in_all
library("openxlsx")
library("Hmisc")
library("tidyverse")
data<-read.xlsx("C:/Users/USER/Desktop/ARG taxon correlation.xlsx",sheet=1,rowNames=T,sep.names=" ")
#計算出現次數
data_clean<-data
data_clean[data_clean!=0]<-1
data_clean$times_discover_in_all<-apply(data_clean,1,sum)
data$times_discover<-data_clean$times_discover_in_all
#這邊可以篩選出現超過幾次的data
times_over8<-filter(data,times_discover>=8)
View(times_over8)
times_over8$times_discover<-NULL
times_over8<-as.data.frame(t(times_over8))
View(times_over8)
#因為rcorr()他的input要是matrix
data.matrix<-as.matrix(data)
corr<-rcorr(data.matrix,type= 'spearman')
#corr<-as.list(corrx)
corr$P[corr$P >= 0.05] <- -1
corr$P[corr$P < 0.05 & corr$P >= 0] <- 1
corr$P[corr$P == -1] <- 0
#我們先輸出一次有顯著相關但相關性未必足夠的矩陣
corr_significiant<-corr$r * corr$P
#因為write.xlsx之output要是dataframe
corr_significiant.dataframe<-as.data.frame(corr_significiant)
write.xlsx(corr_significiant.dataframe, 'C:/Users/USER/Desktop/小型testp0.05.xlsx',rowNames=T,colNames=T,keepNA=T)
data<-read.xlsx("C:/Users/USER/Desktop/ARG taxon correlation.xlsx",sheet=1,rowNames=T,sep.names=" ")
#計算出現次數
data_clean<-data
data_clean[data_clean!=0]<-1
data_clean$times_discover_in_all<-apply(data_clean,1,sum)
data$times_discover<-data_clean$times_discover_in_all
data<-read.xlsx("C:/Users/USER/Desktop/ARG taxon correlation.xlsx",sheet=1,rowNames=T,sep.names=" ")
#計算出現次數
data_clean<-data
data_clean[data_clean!=0]<-1
data_clean$times_discover_in_all<-apply(data_clean,1,sum)
View(data_clean)
#這邊可以篩選出現超過幾次的data
times_over8<-filter(data,times_discover>=8)
data<-read.xlsx("C:/Users/USER/Desktop/ARG taxon correlation.xlsx",sheet=1,rowNames=T,sep.names=" ")
#計算出現次數
data_clean<-data
data_clean[data_clean!=0]<-1
data_clean$times_discover_in_all<-apply(data_clean,1,sum)
data$times_discover<-data_clean$times_discover_in_all
#這邊可以篩選出現超過幾次的data
times_over8<-filter(data,times_discover>=8)
times_over8$times_discover<-NULL
times_over8<-as.data.frame(t(times_over8))
#因為rcorr()他的input要是matrix
data.matrix<-as.matrix(times_over8)
corr<-rcorr(data.matrix,type= 'spearman')
#corr<-as.list(corrx)
corr$P[corr$P >= 0.05] <- -1
corr$P[corr$P < 0.05 & corr$P >= 0] <- 1
corr$P[corr$P == -1] <- 0
#我們先輸出一次有顯著相關但相關性未必足夠的矩陣
corr_significiant<-corr$r * corr$P
#因為write.xlsx之output要是dataframe
corr_significiant.dataframe<-as.data.frame(corr_significiant)
write.xlsx(corr_significiant.dataframe, 'C:/Users/USER/Desktop/小型testp0.05.xlsx',rowNames=T,colNames=T,keepNA=T)
#接著將計算出來之相關性大於0.8且p小於0.05者留下
corr$r[corr$r < 0.8] <- 0
corr_final <-corr$r * corr$P
#因為計算相關性只會有半邊的矩陣(上面是多餘的)所以我們只會需要下三角矩陣，且不需要對角矩陣(都為1)
corr_final[!lower.tri(corr_final)] <- 0
#有些數據因為是0所以算不出相關性(na)，我們把她去除
corr_final[is.na(corr_final)]<-0
corr_final.dataframe<-as.data.frame(corr_final)
write.xlsx(corr_final.dataframe, 'C:/Users/USER/Desktop/小型test.xlsx',rowNames=T,colNames=T)
library("tidyverse")
library("openxlsx")
library("car")
library("FSA")
library("ggsignif")
library("mdthemes")
data<-read.xlsx(xlsxFile = "C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/ARG/argoap_out.xlsx",sheet=2,rowNames=T,colNames=T)
View(data)
#我們先將留下我們想要的DATA，並將組別資訊加到Data中
data<-data[apply(data, 1, function(x) !all(x==0)),]
View(data)
data<-as.data.frame(t(data))
data$sum<-apply(data,1,sum)
data$location<-c("Raw","Raw","Raw","Finished","Finished","Finished","Upstream","Upstream","Upstream","Midstream","Midstream","Midstream","Downstream","Downstream","Downstream")
data$location<-factor(data$location,levels = c("Raw","Finished","Upstream","Midstream","Downstream"))
View(data)
varaible_and_group<-unclassification~location#想測試的變數跟組別
View(data)
varaible_and_group<-unclassified~location#想測試的變數跟組別
Data.levels<-split(data, data$location)
for(i in seq(length(Data.levels))) {
group.n<-length(Data.levels[[i]]$location)
group.name <-Data.levels[[i]]$location[1]
cat(paste("Group: ", group.name, sep=''), sep="", append=TRUE)
if (group.n < 50) {
shapiro.result<- shapiro.test(Data.levels[[i]]$unclassified)
cat(", Shapiro-Wilk normality test W = ", shapiro.result$statistic, " p-value = ", shapiro.result$p.value, "\n" , sep="")
} else {
ks.result<-ks.test(Data.levels[[i]]$sum, pnorm, mean(Data.levels[[i]]$unclassified), sd(Data.levels[[i]]$unclassified))
cat(", Kolmogorov-Smirnov normality test D = ", ks.result$statistic, " p-value = ", ks.result$p.value, "\n" , sep="", append=TRUE)
}
}
#檢查數據變異數的同質性，，如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
homo<-leveneTest(varaible_and_group,data = data)
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#我們必須手動去看是否是常態及同質的，如果兩者皆符合，那我們可以使用t-test
pairwise.t.test(data$unclassified,data$location,p.adjust.method = "BH")
?pairwise.t.test
#如果兩者中有一不符合，那我們得使用wilcoxon rank sum test
pairwise.wilcox.test(data$unclassified,data$location,p.adjust.method = "BH")
data<-read.xlsx(xlsxFile = "C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/ARG/argoap_out.xlsx",sheet=2,rowNames=T,colNames=T)
#我們先將留下我們想要的DATA，並將組別資訊加到Data中
data<-data[apply(data, 1, function(x) !all(x==0)),]
data<-as.data.frame(t(data))
data$sum<-apply(data,1,sum)
data$location<-c("Raw","Raw","Raw","Finished","Finished","Finished","Upstream","Upstream","Upstream","Midstream","Midstream","Midstream","Downstream","Downstream","Downstream")
data$location<-factor(data$location,levels = c("Raw","Finished","Upstream","Midstream","Downstream"))
varaible_and_group<-aminoglycoside~location#想測試的變數跟組別
{#檢查數據是否是常態分布的,利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
Data.levels<-split(data, data$location)
for(i in seq(length(Data.levels))) {
group.n<-length(Data.levels[[i]]$location)
group.name <-Data.levels[[i]]$location[1]
cat(paste("Group: ", group.name, sep=''), sep="", append=TRUE)
if (group.n < 50) {
shapiro.result<- shapiro.test(Data.levels[[i]]$aminoglycoside)
cat(", Shapiro-Wilk normality test W = ", shapiro.result$statistic, " p-value = ", shapiro.result$p.value, "\n" , sep="")
} else {
ks.result<-ks.test(Data.levels[[i]]$sum, pnorm, mean(Data.levels[[i]]$aminoglycoside), sd(Data.levels[[i]]$aminoglycoside))
cat(", Kolmogorov-Smirnov normality test D = ", ks.result$statistic, " p-value = ", ks.result$p.value, "\n" , sep="", append=TRUE)
}
}
#檢查數據變異數的同質性，，如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
homo<-leveneTest(varaible_and_group,data = data)
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#如果不同質可以用ftest來看是誰不同質
#res.ftest <- var.test(Data.levels[[1]]$bacitracin,Data.levels[[4]]$bacitracin,data = data)
#res.ftest
}
#我們必須手動去看是否是常態及同質的，如果兩者皆符合，那我們可以使用t-test
pairwise.t.test(data$aminoglycoside,data$location,p.adjust.method = "BH")
#這邊要在特別注意一下輸入的參數，要調整你的欄名跟列名，sep.names是在設定你要用什麼取代data中的空格
data<-read.xlsx("C:/Users/USER/Desktop/ff.xlsx",sheet=2,rowNames=T)
#相關性檢驗
library(Hmisc)
library("openxlsx")
#這邊要在特別注意一下輸入的參數，要調整你的欄名跟列名，sep.names是在設定你要用什麼取代data中的空格
data<-read.xlsx("C:/Users/USER/Desktop/ff.xlsx",sheet=2,rowNames=T)
library("openxlsx")
#這邊要在特別注意一下輸入的參數，要調整你的欄名跟列名，sep.names是在設定你要用什麼取代data中的空格
data<-read.xlsx("C:/Users/USER/Desktop/argenvcorrelation",sheet=2,rowNames=T)
#相關性檢驗
library(Hmisc)
#因為rcorr()他的input要是matrix
data.matrix<-as.matrix(data)
library("openxlsx")
#這邊要在特別注意一下輸入的參數，要調整你的欄名跟列名，sep.names是在設定你要用什麼取代data中的空格
data<-read.xlsx("C:/Users/USER/Desktop/argenvcorrelation.xlsx",sheet=2,rowNames=T)
#相關性檢驗
library(Hmisc)
#因為rcorr()他的input要是matrix
data.matrix<-as.matrix(data)
corr<-rcorr(data.matrix,type= 'pearson')
#corr<-as.list(corrx)
corr$P[corr$P >= 0.05] <- -1
corr$P[corr$P < 0.05 & corr$P >= 0] <- 1
corr$P[corr$P == -1] <- 0
#我們先輸出一次有顯著相關但相關性未必足夠的矩陣
corr_significiant<-corr$r * corr$P
#因為write.xlsx之output要是dataframe
corr_significiant.dataframe<-as.data.frame(corr_significiant)
write.xlsx(corr_significiant.dataframe, 'C:/Users/USER/Desktop/小型testp0.05.xlsx',rowNames=T,colNames=T,keepNA=T)
