dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
rownames(envata)<-envata$Genus
envata<-envata[,-(1:7)]
dbpata<-as.data.frame(t(dbpata))
envata<-as.data.frame(t(envata))
envata <- decostand(envata, method = 'hellinger')
dbpata<-dbpata[-(1:3),]
envata<-envata[-(1:3),]
groupata<-groupata[-(1:3),]
envata$sum<-apply(envata,1,sum)
envata<-envata%>%
arrange(desc(sum))
envata$sum<-NULL
envata<-envata[1:30,]
envata<-as.data.frame(t(envata))
#dbpata<-dbpata[-c(2,6,11),]
#envata<-envata[-c(2,6,11),]
dist.abund <- vegdist(dbpata, method = "bray")
dist.abund<-as.matrix(dist.abund)
each_column_dist<-envata%>%
summarise_all(~vegdist(.,method = "bray"))%>%
as.data.frame()
dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
rownames(envata)<-envata$Genus
envata<-envata[,-(1:7)]
dbpata<-as.data.frame(t(dbpata))
envata<-as.data.frame(t(envata))
dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
rownames(envata)<-envata$Genus
envata<-envata[,-(1:7)]
dbpata<-as.data.frame(t(dbpata))
envata<-as.data.frame(t(envata))
envata <- decostand(envata, method = 'hellinger')
dbpata<-dbpata[-(1:3),]
envata<-envata[-(1:3),]
groupata<-groupata[-(1:3),]
envata$sum<-apply(envata,1,sum)
envata<-envata%>%
arrange(desc(sum))
envata$sum<-NULL
envata<-envata[1:30,]
envata<-as.data.frame(t(envata))
#dbpata<-dbpata[-c(2,6,11),]
#envata<-envata[-c(2,6,11),]
dist.abund <- vegdist(dbpata, method = "bray")
envata.abund <- vegdist(envata, method = "bray")
dist.abund<-as.matrix(dist.abund)
envata.abund <-as.matrix(envata.abund)
each_column_dist<-envata%>%
summarise_all(~vegdist(.,method = "bray"))%>%
as.data.frame()
dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
rownames(envata)<-envata$Genus
envata<-envata[,-(1:7)]
dbpata<-dbpata[apply(dbpata, 1, function(x) !all(x==0)),]
dbpata<-as.data.frame(t(dbpata))
envata<-as.data.frame(t(envata))
envata <- decostand(envata, method = 'hellinger')
dbpata<-dbpata[-(1:3),]
envata<-envata[-(1:3),]
groupata<-groupata[-(1:3),]
#dbpata<-dbpata[-c(2,6,11),]
#envata<-envata[-c(2,6,11),]
dist.abund <- vegdist(dbpata, method = "bray")
envata.abund <- vegdist(envata, method = "bray")
dist.abund<-as.matrix(dist.abund)
envata.abund <-as.matrix(envata.abund)
mantel(envata.abund,dist.abund,method = "spearman", permutations = 9999, na.rm = TRUE)
dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
rownames(envata)<-envata$Genus
envata<-envata[,-(1:7)]
dbpata<-dbpata[apply(dbpata, 1, function(x) !all(x==0)),]
dbpata<-as.data.frame(t(dbpata))
dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
rownames(envata)<-envata$Genus
envata<-envata[,-(1:7)]
dbpata<-dbpata[apply(dbpata, 1, function(x) !all(x==0)),]
dbpata<-as.data.frame(t(dbpata))
envata <- decostand(envata, method = 'hellinger')
dbpata<-dbpata[-(1:3),]
envata<-envata[-(1:3),]
dbpata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/ARGoap_out.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
groupata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/groupdata.xlsx",sheet=1,rowNames=T,colNames=T,sep.names=" ")
envata<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/TAXA/rel abundance table/genus_rel_table.xlsx",sheet=1,rowNames=F,colNames=T,sep.names=" ")
rownames(envata)<-envata$Genus
envata<-envata[,-(1:7)]
dbpata<-dbpata[apply(dbpata, 1, function(x) !all(x==0)),]
dbpata<-as.data.frame(t(dbpata))
envata <- decostand(envata, method = 'hellinger')
dbpata<-dbpata[-(1:3),]
envata<-envata[,-(1:3)]
groupata<-groupata[-(1:3),]
envata$sum<-apply(envata,1,sum)
envata<-envata%>%
arrange(desc(sum))
envata$sum<-NULL
envata<-envata[1:30,]
envata<-as.data.frame(t(envata))
#dbpata<-dbpata[-c(2,6,11),]
#envata<-envata[-c(2,6,11),]
dist.abund <- vegdist(dbpata, method = "bray")
envata.abund <- vegdist(envata, method = "bray")
dist.abund<-as.matrix(dist.abund)
envata.abund <-as.matrix(envata.abund)
each_column_dist<-envata%>%
summarise_all(~vegdist(.,method = "bray"))%>%
as.data.frame()
View(envata)
mantel(envata.abund,dist.abund,method = "spearman", permutations = 9999, na.rm = TRUE)
mantel(envata.abund,dist.abund,method = "pearson", permutations = 9999, na.rm = TRUE)
spearman
?summarise_all
each_column_dist<-envata%>%
summarise_all(~vegdist(.,method = "bray"))
View(each_column_dist)
envata1<-envata
envata1$g__Polycladomycesvegdist(envata$g__Polycladomyces, method = "bray")
envata1$g__Polycladomyces<-vegdist(envata$g__Polycladomyces, method = "bray")
envata1<-vegdist(envata$g__Polycladomyces, method = "bray")
as.matrix(envata1)
View(dist.abund)
each_column_dist<-envata%>%
summarise_all(~vegdist(.,method = "bray"))%>%
as.list()
View(each_column_dist)
for(i in 1:n){
x<-mantel(each_column_dist[i],dist.abund, method = "spearman", permutations = 9999, na.rm = TRUE)
df[1,i]<-x$statistic
df[2,i]<-x$signif
}
View(each_column_dist)
View(dbpata)
View(envata)
each_column_dist<-envata%>%
summarise_all(~vegdist(.,method = "bray"))
View(each_column_dist)
View(dist.abund)
View(envata)
each_column_dist<-envata%>%
summarise_all(~vegdist(.,method = "bray"))%>%
as.data.frame()
#dbpata<-dbpata[-c(2,6,11),]
#envata<-envata[-c(2,6,11),]
dist.abund <- vegdist(dbpata, method = "bray")
mantel.pairwise<-function(){
df<- data.frame()
n<-length(colnames(envata))
for(i in 1:n){
x<-mantel(each_column_dist[,i],dist.abund, method = "spearman", permutations = 9999, na.rm = TRUE)
df[1,i]<-x$statistic
df[2,i]<-x$signif
}
colnames(df)<-colnames(each_column_dist)
rownames(df)<-c("Mantel statistic r","Significance")
assign("mantel_output",df,envir = globalenv())
}
mantel.pairwise()
View(mantel_output)
View(mantel_output)
library("PMCMRplus")
library("dplyr")
library("tidyverse")
library("openxlsx")
library("stringr")
library("car")
library("FSA")
library("RColorBrewer")
library("ggsignif")
library("mdthemes")
data<-read.xlsx(xlsxFile = "C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARG/argoap_out.xlsx",sheet=2,rowNames=T,colNames=T)
#目的:比對某參數在兩個季節採樣間是否有顯著差異(排除原水)
data<-data[apply(data, 1, function(x) !all(x==0)),]
data<-as.data.frame(t(data))
data$sum<-apply(data,1,sum)
data$location<-c("Raw","Raw","Raw","Finished","Finished","Finished","Upstream","Upstream","Upstream","Midstream","Midstream","Midstream","Downstream","Downstream","Downstream")
data$location<-factor(data$location,levels = c("Raw","Finished","Upstream","Midstream","Downstream"))
View(data)
varaible_and_group<-bacitracin~location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
varaible_and_group<-multidrug~location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
varaible_and_group<-tetracycline~location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
#以下開始繪圖，先計算平均跟標準差，其實這部不是必要
varaible_group_mean<-data%>%
group_by(type)%>%
summarise(type_mean=mean(Temperature,na.rm=T),type_sd=sd(Temperature))
varaible_and_group<-tetracyclin~location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
varaible_and_group<-tetracycline~location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
View(data)
View(data)
colnames(data)[colnames(data)=="macrolide-lincosamide-streptogramin"]<-"MLS"
colnames(data)[colnames(data)=="beta-lactam"]<-"BL"
varaible_and_group<-BL~location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
varaible_and_group<-unclassified~location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
#以下開始繪圖，先計算平均跟標準差，其實這部不是必要
varaible_group_mean<-data%>%
group_by(type)%>%
summarise(type_mean=mean(Temperature,na.rm=T),type_sd=sd(Temperature))
