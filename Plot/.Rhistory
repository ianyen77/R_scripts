ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F9B282", size=4,alpha=0.5) +
theme_bw() +
xlab("Sample") +
ylab("Metacompare Risk Score")
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F9B282", size=4,alpha=0.7) +
theme_bw() +
xlab("Sample") +
ylab("Metacompare Risk Score")
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +
theme_bw() +
xlab("Sample") +
ylab("Metacompare Risk Score")
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +geom_text()
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +geom_text(x=Location, y=Risk.Score+1,label=Risk.Score)
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +geom_text(x=Location, y=Risk.Score+1,label=Risk.Score)
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +geom_text(aes(x=Location, y=Risk.Score+1,label=Risk.Score))
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +geom_text(aes(x=Location, y=Risk.Score+1,label=Risk.Score))+
theme_bw() +
xlab("Sample") +
ylab("Metacompare Risk Score")
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +geom_text(aes(x=Location, y=Risk.Score+1,label=Risk.Score))+
theme_bw() +
xlab("Sample") +
ylab("Metacompare Risk Score")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
#lolipop plot
ggplot(data1) +
geom_segment(aes(x=Location, xend=Location, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Location, y=Risk.Score),color="#F3E79A", size=4,alpha=0.8) +geom_text(aes(x=Location, y=Risk.Score+1,label=Risk.Score))+
theme_bw() +
xlab("Sample") +
ylab("Metacompare Risk Score")+
ggtitle("Location Co-Assembly Metacompare Risk Score")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
#3d scatter
s3d<-scatterplot3d(data1[,1:3],main="Metacompare risk Matrix Scores",color= color1,pch=18,cex.symbols = 2,type="h",grid=T)
text(s3d$xyz.convert(data1[,1:3]),adj=0.2,pos=3,labels =data1[,4],cex= 0.66, col = "black")
legend("bottom",col=color1,legend=levels(data1$Location),pt.bg = color1,pch=18,inset=-0.17,xpd =T,horiz = T)
color2<-hcl.colors(5,"sunset")
#3d scatter
s3d<-scatterplot3d(data1[,1:3],main="Metacompare risk Matrix Scores",color= color2,pch=18,cex.symbols = 2,type="h",grid=T)
text(s3d$xyz.convert(data1[,1:3]),adj=0.2,pos=3,labels =data1[,4],cex= 0.66, col = "black")
legend("bottom",col=color1,legend=levels(data1$Location),pt.bg = color1,pch=18,inset=-0.17,xpd =T,horiz = T)
legend("bottom",col=color2,legend=levels(data1$Location),pt.bg = color1,pch=18,inset=-0.17,xpd =T,horiz = T)
library(openxlsx)
library(scatterplot3d)
library(tidyverse)
library(ggplot2)
##Indivisual assembly visulazation-----------------------------------------
data<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARC_analysis/Metacompare/Metacompare.xlsx",sheet=2,rowNames=F,colNames = T)
data1<-data[,c(9,12,13)]
data1<-log10(data1[,1:3])
data1$Risk.Score<-data$Risk.Score
data1$Risk.Score<-round(data$Risk.Score,1)
color1<-c("#FB8072","#80B1D3","#BEBADA","#FDB462","#B3DE69")
color<-rep(color1,each=3)
color2<-hcl.colors(5,"sunset")
colo2<-rep(color2,each=3)
data1$Location<-data$Location
data1$Location<-factor(data1$Location,levels =c("Raw","Finished","Upstream","Midstream","Downstream"))
#hazard space
s3d<-scatterplot3d(data1[,1:3],main="Metacompare risk Matrix Scores",color= color,pch=18,cex.symbols = 2,type="h",grid=T)
text(s3d$xyz.convert(data1[,1:3]),adj=0.2,pos=3,labels =data1[,4],cex= 0.66, col = "black")
legend("bottom",col=color1,legend=levels(data1$Location),pt.bg = color1,pch=18,inset=-0.17,xpd =T,horiz = T)
#bar plot
data_barplot<-data%>%
group_by(Location)%>%
summarise(mean=mean(Risk.Score),std=sd(Risk.Score))
data_barplot$Location<-factor(data_barplot$Location,levels =c("Raw","Finished","Upstream","Midstream","Downstream"))
bar_plot<-ggplot(data_barplot,aes(x=Location,y=mean))+geom_bar(alpha=0.7,stat = "identity",width = 0.8,fill="#F3E79A")+theme_bw()+geom_errorbar(aes(x=Location,ymin=mean-std, ymax=mean+std), width=.1,position=position_dodge(.9))+labs(x="Location",y="MetaCompare Risk Scores")+theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
bar_plot
bar_plot<-ggplot(data_barplot,aes(x=Location,y=mean))+geom_bar(alpha=0.7,stat = "identity",width = 0.8,fill="#F3E79A")+theme_bw()+geom_errorbar(aes(x=Location,ymin=mean-std, ymax=mean+std), width=.1,position=position_dodge(.9))+labs(x="Location",y="MetaCompare Risk Scores",title = "Individual Assembly Risk Scores ")+theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
bar_plot<-ggplot(data_barplot,aes(x=Location,y=mean))+geom_bar(alpha=0.7,stat = "identity",width = 0.8,fill="#F3E79A")+theme_bw()+geom_errorbar(aes(x=Location,ymin=mean-std, ymax=mean+std), width=.1,position=position_dodge(.9))+labs(x="Location",y="MetaCompare Risk Scores",title = "Individual Assembly Risk Scores")+theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
bar_plot
library(openxlsx)
library(scatterplot3d)
library(tidyverse)
library(ggplot2)
##Indivisual assembly visulazation-----------------------------------------
data<-read.xlsx("C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARC_analysis/Metacompare/Metacompare.xlsx",sheet=2,rowNames=F,colNames = T)
data1<-data[,c(9,12,13)]
data1<-log10(data1[,1:3])
data1$Risk.Score<-data$Risk.Score
data1$Risk.Score<-round(data$Risk.Score,1)
color1<-c("#FB8072","#80B1D3","#BEBADA","#FDB462","#B3DE69")
color<-rep(color1,each=3)
color2<-hcl.colors(5,"sunset")
colo2<-rep(color2,each=3)
data1$Location<-data$Location
data1$Location<-factor(data1$Location,levels =c("Raw","Finished","Upstream","Midstream","Downstream"))
#hazard space
s3d<-scatterplot3d(data1[,1:3],main="Metacompare risk Matrix Scores",color= color,pch=18,cex.symbols = 2,type="h",grid=T)
text(s3d$xyz.convert(data1[,1:3]),adj=0.2,pos=3,labels =data1[,4],cex= 0.66, col = "black")
legend("bottom",col=color1,legend=levels(data1$Location),pt.bg = color1,pch=18,inset=-0.17,xpd =T,horiz = T)
#bar plot
data_barplot<-data%>%
group_by(Location)%>%
summarise(mean=mean(Risk.Score),std=sd(Risk.Score))
data_barplot$Location<-factor(data_barplot$Location,levels =c("Raw","Finished","Upstream","Midstream","Downstream"))
bar_plot<-ggplot(data_barplot,aes(x=Location,y=mean))+geom_bar(alpha=0.7,stat = "identity",width = 0.8,fill="#F3E79A")+theme_bw()+geom_errorbar(aes(x=Location,ymin=mean-std, ymax=mean+std), width=.1,position=position_dodge(.9))+labs(x="Location",y="MetaCompare Risk Scores",title = "Individual Assembly Risk Scores")+theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
bar_plot
#lolipop plot
data1$Sample<-data$Sample
ggplot(data1) +
geom_segment(aes(x=Sample, xend=Sample, y=0, yend=Risk.Score), color="grey")+
geom_point( aes(x=Sample, y=Risk.Score),color="#704D9E", size=4,alpha=0.5) +
theme_bw() +
xlab("Sample") +
ylab("Metacompare Risk Score")
View(data1)
varaible_and_group<-Risk.Score~Location#想測試的變數跟組別
{#檢查數據是否是常態分布的,利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
Data.levels<-split(data1, data$location)
for(i in seq(length(Data.levels))) {
group.n<-length(Data.levels[[i]]$location)
group.name <-Data.levels[[i]]$location[1]
cat(paste("Group: ", group.name, sep=''), sep="", append=TRUE)
if (group.n < 50) {
shapiro.result<- shapiro.test(Data.levels[[i]]$sum)
cat(", Shapiro-Wilk normality test W = ", shapiro.result$statistic, " p-value = ", shapiro.result$p.value, "\n" , sep="")
} else {
ks.result<-ks.test(Data.levels[[i]]$sum, pnorm, mean(Data.levels[[i]]$sum), sd(Data.levels[[i]]$sum))
cat(", Kolmogorov-Smirnov normality test D = ", ks.result$statistic, " p-value = ", ks.result$p.value, "\n" , sep="", append=TRUE)
}
}
#檢查數據變異數的同質性，，如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
homo<-leveneTest(varaible_and_group,data = data)
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#如果不同質可以用ftest來看是誰不同質
#res.ftest <- var.test(Data.levels[[1]]$bacitracin,Data.levels[[4]]$bacitracin,data = data)
#res.ftest
}
{#檢查數據是否是常態分布的,利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
Data.levels<-split(data1, data$location)
for(i in seq(length(Data.levels))) {
group.n<-length(Data.levels[[i]]$location)
group.name <-Data.levels[[i]]$location[1]
cat(paste("Group: ", group.name, sep=''), sep="", append=TRUE)
if (group.n < 50) {
shapiro.result<- shapiro.test(Data.levels[[i]]$Risk.Score)
cat(", Shapiro-Wilk normality test W = ", shapiro.result$statistic, " p-value = ", shapiro.result$p.value, "\n" , sep="")
} else {
ks.result<-ks.test(Data.levels[[i]]$Risk.Score, pnorm, mean(Data.levels[[i]]$Risk.Score), sd(Data.levels[[i]]$Risk.Score))
cat(", Kolmogorov-Smirnov normality test D = ", ks.result$statistic, " p-value = ", ks.result$p.value, "\n" , sep="", append=TRUE)
}
}
#檢查數據變異數的同質性，，如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
homo<-leveneTest(varaible_and_group,data = data1)
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#如果不同質可以用ftest來看是誰不同質
#res.ftest <- var.test(Data.levels[[1]]$bacitracin,Data.levels[[4]]$bacitracin,data = data)
#res.ftest
}
Data.levels<-split(data1, data$Location)
{#檢查數據是否是常態分布的,利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
Data.levels<-split(data1, data$Location)
for(i in seq(length(Data.levels))) {
group.n<-length(Data.levels[[i]]$Location)
group.name <-Data.levels[[i]]$Location[1]
cat(paste("Group: ", group.name, sep=''), sep="", append=TRUE)
if (group.n < 50) {
shapiro.result<- shapiro.test(Data.levels[[i]]$Risk.Score)
cat(", Shapiro-Wilk normality test W = ", shapiro.result$statistic, " p-value = ", shapiro.result$p.value, "\n" , sep="")
} else {
ks.result<-ks.test(Data.levels[[i]]$Risk.Score, pnorm, mean(Data.levels[[i]]$Risk.Score), sd(Data.levels[[i]]$Risk.Score))
cat(", Kolmogorov-Smirnov normality test D = ", ks.result$statistic, " p-value = ", ks.result$p.value, "\n" , sep="", append=TRUE)
}
}
#檢查數據變異數的同質性，，如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
homo<-leveneTest(varaible_and_group,data = data1)
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#如果不同質可以用ftest來看是誰不同質
#res.ftest <- var.test(Data.levels[[1]]$bacitracin,Data.levels[[4]]$bacitracin,data = data)
#res.ftest
}
library("car")
library("FSA")
{#檢查數據是否是常態分布的,利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
Data.levels<-split(data1, data$Location)
for(i in seq(length(Data.levels))) {
group.n<-length(Data.levels[[i]]$Location)
group.name <-Data.levels[[i]]$Location[1]
cat(paste("Group: ", group.name, sep=''), sep="", append=TRUE)
if (group.n < 50) {
shapiro.result<- shapiro.test(Data.levels[[i]]$Risk.Score)
cat(", Shapiro-Wilk normality test W = ", shapiro.result$statistic, " p-value = ", shapiro.result$p.value, "\n" , sep="")
} else {
ks.result<-ks.test(Data.levels[[i]]$Risk.Score, pnorm, mean(Data.levels[[i]]$Risk.Score), sd(Data.levels[[i]]$Risk.Score))
cat(", Kolmogorov-Smirnov normality test D = ", ks.result$statistic, " p-value = ", ks.result$p.value, "\n" , sep="", append=TRUE)
}
}
#檢查數據變異數的同質性，，如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
homo<-leveneTest(varaible_and_group,data = data1)
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#如果不同質可以用ftest來看是誰不同質
#res.ftest <- var.test(Data.levels[[1]]$bacitracin,Data.levels[[4]]$bacitracin,data = data)
#res.ftest
}
#我們必須手動去看是否是常態及同質的，如果兩者皆符合，那我們可以使用t-test
pairwise.t.test(data1$Risk.Score,data$Location,p.adjust.method = "BH")
#我們必須手動去看是否是常態及同質的，如果兩者皆符合，那我們可以使用t-test
pairwise.t.test(data1$Risk.Score,data$Location)
varaible_and_group<-Risk.Score~Location#想測試的變數跟組別
##ANOVA
data<-dat1
##ANOVA
data<-data1
varaible_and_group<-Risk.Score~Location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
#檢查數據變異數的同質性，可以使用levenes test
#如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
{homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
#如果沒問題(常態且同質)就可以看ANOVA的結果了
if (a["p.value"]>0.05 && homo$`Pr(>F)`[1]>0.05){
#如果p<0.05，那表是多組間的差距是不同的，那我們可以用事後檢定來看到底是誰不一樣
print ("we can use anova ")
anova_p<-summary(res.aov)
if (anova_p[[1]]$`Pr(>F)`[1]<0.05){
print ("anova p<0.05, use TukeyHSD")
TukeyHSD(res.aov)
}else{
print("anova p>0.05,difference is insignificiant")
}
}else{
#數據在anova的兩項假設中有一項不符合，因此我們要使用kruskal-wallis來檢定
print ("use kruskal wallise rank sum test")
kruskal_output<-kruskal.test(varaible_and_group, data = data)
if (kruskal_output$p.value< 0.05){
#kruskal-wallis 檢定 p <0.05，表示組間有差距，因此我們要使用事後檢定
#我們可以使用Dunntest來看看是哪一組不同
PT = dunnTest(varaible_and_group, data = data,
method="bh")    # Can adjust p-values;
print (PT)
}else{
print ("kruskal-wallis p>0.05,difference is insignificiant")
}
}
}
homo<-leveneTest(varaible_and_group,data = data)
homo
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#接著檢查數據是否是常態分布的
res.aov <- aov(varaible_and_group, data = data)
plot(res.aov,2)#這個是QQplot 可以透過這張圖來看一下有哪些點可以拿掉。
aov_residuals <- residuals(object = res.aov )
#利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
a<-shapiro.test(x = aov_residuals)
if(a["p.value"]>0.05){
print("data is normal distribution")
}else{print("data is  not a normal distribution")}
a["p.value"]
varaible_and_group<-Risk.Score~Location#想測試的變數跟組別
#我們必須先檢查數據是不是常態分布及變異數的同質性，才能決定我們要用的檢定方法。
{#檢查數據是否是常態分布的,利用shapiro.test來檢驗數據是不是常態的，如果p>0.05那麼數據就是常態的
Data.levels<-split(data1, data$Location)
for(i in seq(length(Data.levels))) {
group.n<-length(Data.levels[[i]]$Location)
group.name <-Data.levels[[i]]$Location[1]
cat(paste("Group: ", group.name, sep=''), sep="", append=TRUE)
if (group.n < 50) {
shapiro.result<- shapiro.test(Data.levels[[i]]$Risk.Score)
cat(", Shapiro-Wilk normality test W = ", shapiro.result$statistic, " p-value = ", shapiro.result$p.value, "\n" , sep="")
} else {
ks.result<-ks.test(Data.levels[[i]]$Risk.Score, pnorm, mean(Data.levels[[i]]$Risk.Score), sd(Data.levels[[i]]$Risk.Score))
cat(", Kolmogorov-Smirnov normality test D = ", ks.result$statistic, " p-value = ", ks.result$p.value, "\n" , sep="", append=TRUE)
}
}
#檢查數據變異數的同質性，，如果levenes test 的結果p>0.05，那我們可以認為以這幾個組別間的變異數沒有明顯差異，他們是同質的P
homo<-leveneTest(varaible_and_group,data = data1)
if (homo$`Pr(>F)`[1]>0.05){
print("data is homo")
}else{print ("data is nonhomo")}
#如果不同質可以用ftest來看是誰不同質
#res.ftest <- var.test(Data.levels[[1]]$bacitracin,Data.levels[[4]]$bacitracin,data = data)
#res.ftest
}
#我們必須手動去看是否是常態及同質的，如果兩者皆符合，那我們可以使用t-test
pairwise.t.test(data1$Risk.Score,data$Location)
library(openxlsx)
library(tidyverse)
library(ggpubr)
##ARG-like ORF coverage
file_path <- "C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARC/indivisual assembly/ARC_sm70/ARC_ORF/ARG_orf_coverage/ARG_lik_orf_coverage/"
file_list <- list.files(path = file_path, pattern = ".xlsx", full.names = TRUE)
df2 <- map_dfr(file_list, ~{
read.xlsx(.x) %>%
select(orf_coverage) %>%
summarise(sum_ARG_coverage = sum(orf_coverage)) %>%
mutate(filename = str_remove(.x, ".xlsx"))%>%
mutate(filename = str_replace(filename, ".*/", ""))#%>%
#column_to_rownames(var = "filename")
})
##因為有兩個sample 沒有比對到ARG，所以我們手動幫她加入
new_row <- data.frame(sum_ARG_coverage=c(0,0) ,filename =c("T4-W-2ARG_like_orf_cov_all","T4-W-3ARG_like_orf_cov_all"))
df2<- rbind(slice(df2, 1:10), new_row, slice(df2, 11:13))
##MGE-like ORF coverage
file_path <- "C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARC/indivisual assembly/MGE_coverage/MGE_lik_orf_coverage/"
file_list <- list.files(path = file_path, pattern = ".xlsx", full.names = TRUE)
df3 <- map_dfr(file_list, ~{
read.xlsx(.x) %>%
select(orf_coverage) %>%
summarise(sum_MGE_coverage = sum(orf_coverage)) %>%
mutate(filename = str_remove(.x, ".xlsx"))%>%
mutate(filename = str_replace(filename, ".*/", ""))#%>%
#column_to_rownames(var = "filename")
})
x<-data.frame(ARG=df2$sum_ARG_coverage,MGE=df3$sum_MGE_coverage)
#contig number
x$ncontig<-c(90354,91885,113099,290322,307908,282737,57459,99158,60933,11284,11654,4449,18765,17889,13120)
#orf number
x$norf<-c(145709,150952,189623,443161,448192,432003,100355,144837,144837,31880,23860,9656,57648,51512,38876)
#Normaliztion coverage with contig number
x<-x%>%
mutate(A_ncontig=ARG/ncontig)%>%
mutate(M_ncontig=MGE/ncontig)
#sample selection
x1<-x[-(1:6),]
x2<-x[-(1:3),]
X$group<-rep(c("Raw","Finished","Upstream","Midstream","Downstream"),each=3)
library(openxlsx)
library(tidyverse)
library(ggpubr)
##ARG-like ORF coverage
file_path <- "C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARC/indivisual assembly/ARC_sm70/ARC_ORF/ARG_orf_coverage/ARG_lik_orf_coverage/"
file_list <- list.files(path = file_path, pattern = ".xlsx", full.names = TRUE)
df2 <- map_dfr(file_list, ~{
read.xlsx(.x) %>%
select(orf_coverage) %>%
summarise(sum_ARG_coverage = sum(orf_coverage)) %>%
mutate(filename = str_remove(.x, ".xlsx"))%>%
mutate(filename = str_replace(filename, ".*/", ""))#%>%
#column_to_rownames(var = "filename")
})
##因為有兩個sample 沒有比對到ARG，所以我們手動幫她加入
new_row <- data.frame(sum_ARG_coverage=c(0,0) ,filename =c("T4-W-2ARG_like_orf_cov_all","T4-W-3ARG_like_orf_cov_all"))
df2<- rbind(slice(df2, 1:10), new_row, slice(df2, 11:13))
##MGE-like ORF coverage
file_path <- "C:/Users/USER/Desktop/lab/實驗/Metagenomic in DWDS/DATA/newDATA/ARC/indivisual assembly/MGE_coverage/MGE_lik_orf_coverage/"
file_list <- list.files(path = file_path, pattern = ".xlsx", full.names = TRUE)
df3 <- map_dfr(file_list, ~{
read.xlsx(.x) %>%
select(orf_coverage) %>%
summarise(sum_MGE_coverage = sum(orf_coverage)) %>%
mutate(filename = str_remove(.x, ".xlsx"))%>%
mutate(filename = str_replace(filename, ".*/", ""))#%>%
#column_to_rownames(var = "filename")
})
x<-data.frame(ARG=df2$sum_ARG_coverage,MGE=df3$sum_MGE_coverage)
#contig number
x$ncontig<-c(90354,91885,113099,290322,307908,282737,57459,99158,60933,11284,11654,4449,18765,17889,13120)
#orf number
x$norf<-c(145709,150952,189623,443161,448192,432003,100355,144837,144837,31880,23860,9656,57648,51512,38876)
#Normaliztion coverage with contig number
x<-x%>%
mutate(A_ncontig=ARG/ncontig)%>%
mutate(M_ncontig=MGE/ncontig)
x$group<-rep(c("Raw","Finished","Upstream","Midstream","Downstream"),each=3)
source("~/GitHub/R_scripts/Plot/ARG_orf_MGE_orfcoverage.R.R", echo=TRUE)
ggplot(data = x,aes(x=M_ncontig,y=A_ncontig,color=group,fill=group))+
geom_point(size=3,alpha=0.7)+geom_smooth(method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
x$group<-rep(c("Raw","Raw","Raw","Finished","Finished","Finished","DWDS","DWDS","DWDS","DWDS","DWDS","DWDS","DWDS","DWDS","DWDS"))
#sample selection
x1<-x[-(1:6),]
x2<-x[-(1:3),]
ggplot(data = x,aes(x=M_ncontig,y=A_ncontig,color=group,fill=group))+
geom_point(size=3,alpha=0.7)+geom_smooth(method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
ggplot(data = x,aes(x=MGE,y=ARG,color=group,fill=group))+
geom_point(size=3,alpha=0.7)+geom_smooth(method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
x$group2<-rep(c("Raw","Raw","Raw","DW","DW","DW","DW","DW","DW","DW","DW","DW","DW","DW","DW"))
ggplot(data = x,aes(x=MGE,y=ARG,color=group2,fill=group2))+
geom_point(size=3,alpha=0.7)+geom_smooth(method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
ggplot(data = x,aes(x=MGE,y=ARG,color=group1,fill=group1))+
geom_point(size=3,alpha=0.7)+geom_smooth(method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
ggplot(data = x,aes(x=MGE,y=ARG,color=group,fill=group))+
geom_point(size=3,alpha=0.7)+geom_smooth(method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
ggplot(data = x,aes(x=MGE,y=ARG))+
geom_point(size=3,alpha=0.7)+geom_smooth(method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
ggplot(data = x,aes(x=MGE,y=ARG))+
geom_point(color=  "#80B1D3",size=3,alpha=0.7)+geom_smooth(color=  "#80B1D3",method =lm,alpha=0.3) +theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
##ggscatter---------------------
ggscatter(data=x2,x="M_ncontig",y="A_ncontig",color=group,fill=group,add = "reg.line", conf.int = TRUE,  color=  "#80B1D3",alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(method = "pearson", label.x =0.15, label.y = 0.001)+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
##ggscatter---------------------
ggscatter(data=x2,x="M_ncontig",y="A_ncontig",color=group,fill=group,add = "reg.line", conf.int = TRUE,alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(method = "pearson", label.x =0.15, label.y = 0.001)+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
##ggscatter---------------------
ggscatter(data=x,x="M_ncontig",y="A_ncontig",color=group,fill=group,add = "reg.line", conf.int = TRUE,alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(method = "pearson", label.x =0.15, label.y = 0.001)+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
##ggscatter---------------------
ggscatter(data=x,x="M_ncontig",y="A_ncontig",color="group",fill="group",add = "reg.line", conf.int = TRUE,alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(method = "pearson", label.x =0.15, label.y = 0.001)+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
##ggscatter---------------------
ggscatter(data=x,x="M_ncontig",y="A_ncontig",color="group",fill="group",add = "reg.line", conf.int = TRUE,alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(method = "pearson", label.x =0.15, label.y = 0.001,group=group)+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
##ggscatter---------------------
ggscatter(data=x,x="M_ncontig",y="A_ncontig",color="group",fill="group",add = "reg.line", conf.int = TRUE,alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(method = "pearson", label.x =0.15, label.y = 0.001,group="group")+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
stat_cor(method = "pearson", label.x =0.15, label.y = 0.001,group="group")
##ggscatter---------------------
ggscatter(data=x,x="M_ncontig",y="A_ncontig",color="group",fill="group",add = "reg.line", conf.int = TRUE,alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(aes(color=group),method = "pearson", label.x =0.15, label.y = 0.001)+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
##ggscatter---------------------
ggscatter(data=x,x="M_ncontig",y="A_ncontig",color="group",fill="group",add = "reg.line", conf.int = TRUE,alpha=0.7,size=3,
add.params = list(fill = "lightgray"))+stat_cor(aes(color=group),method = "pearson")+theme_bw()+labs(x="Total MGE-like ORF coverage against contig number(x/GB)",y="Total ARG-like ORF coverage against contig number(x/GB)")+
theme(axis.title = element_text(size=13),axis.text =element_text(size=12.5)  ,legend.title= element_text(size=12),legend.text = element_text(size=12))
